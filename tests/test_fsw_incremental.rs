//! Integration test for File System Watcher (FSW) + Incremental Indexing
//!
//! This test verifies that:
//! 1. File changes are detected by FSW
//! 2. Index is updated automatically (NO manual index calls)
//! 3. Search results reflect changes immediately after FSW processes
//! 4. Deletions are also detected and removed from index
//!
//! Critical: This test simulates the MCP server workflow by using
//! the same search functions that MCP tools would use.

use codesearch::chunker::SemanticChunker;
use codesearch::embed::{EmbeddingService, ModelType};
use codesearch::file::FileWalker;
use codesearch::index::manager::{IndexManager, SharedStores};
use codesearch::search::{search_hybrid, SearchOptions};
use codesearch::watch::FileWatcher;
use std::fs::{self, File};
use std::io::Write;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::thread;
use std::time::Duration;
use tempfile::TempDir;

/// Test project setup with real code
fn create_test_project() -> TempDir {
    let temp_dir = TempDir::new().expect("Failed to create temp dir");

    // Create lib.rs with the real test code
    let lib_rs = temp_dir.path().join("lib.rs");
    fs::write(&lib_rs, include_str!("test_fsw_project/lib.rs"))
        .expect("Failed to write test library");

    temp_dir
}

/// Helper function to append content to a file
fn append_to_file(path: &Path, content: &str) {
    let mut file = File::options()
        .append(true)
        .open(path)
        .expect("Failed to open file for writing");
    file.write_all(content.as_bytes())
        .expect("Failed to write to file");
    file.flush().expect("Failed to flush file");
}

/// Helper function to read last N lines of a file
fn read_last_lines(path: &Path, n: usize) -> Vec<String> {
    let content = fs::read_to_string(path).expect("Failed to read file");
    content
        .lines()
        .rev()
        .take(n)
        .map(|s| s.to_string())
        .collect()
}

/// Remove last N lines from a file
fn remove_last_lines(path: &Path, n: usize) -> usize {
    let content = fs::read_to_string(path).expect("Failed to read file");
    let lines: Vec<&str> = content.lines().collect();

    let lines_to_keep = if lines.len() > n {
        &lines[..lines.len() - n]
    } else {
        &lines[..0]
    };

    let new_content = lines_to_keep.join("\n") + "\n";
    fs::write(path, new_content).expect("Failed to write file");
    lines_to_keep.len()
}

#[test]
#[ignore] // This test requires embedding model download - run with: cargo test -- --ignored
fn test_fsw_incremental_indexing() {
    // Step 1: Create test project
    let temp_dir = create_test_project();
    let codebase_path = temp_dir.path();
    let db_path = codebase_path.join(".codesearch.db");

    println!("üìÅ Test project created at: {}", codebase_path.display());

    // Step 2: Create initial index (simulating `codesearch index`)
    // Note: In real MCP server, this is done by incremental_index() in IndexManager::new()
    let model = ModelType::default();
    let dimensions = model.dimensions();

    println!(
        "üîß Creating initial index with {} dimensions...",
        dimensions
    );

    // Create shared stores
    let stores =
        Arc::new(SharedStores::new(&db_path, dimensions).expect("Failed to create shared stores"));

    // Perform initial indexing
    let walker = FileWalker::new(codebase_path);
    let (files, _stats) = walker.walk().expect("Failed to walk files");

    println!("üìÑ Found {} files to index", files.len());

    // Index all files
    {
        let vector_store = stores.vector_store.read().await;
        let fts_store = stores.fts_store.read().await;
        let embedding_service = EmbeddingService::new(model).unwrap();
        let chunker = SemanticChunker::new();

        for file in files {
            let content = fs::read_to_string(&file.path).unwrap();
            let chunks = chunker.chunk(&file.path, &content).unwrap();

            for chunk in chunks {
                let embedding = embedding_service.embed(&chunk.text).unwrap();
                vector_store.add_chunk(&chunk, &embedding).unwrap();
                fts_store.add_chunk(&chunk).unwrap();
            }
        }
    }

    // Step 3: Verify initial search works
    let lib_rs = codebase_path.join("lib.rs");
    let search_opts = SearchOptions {
        query: "authentication user login".to_string(),
        max_results: 5,
        ..Default::default()
    };

    let initial_results =
        search_hybrid(&stores.vector_store, &stores.fts_store, &search_opts, model)
            .expect("Initial search failed");

    println!("üîç Initial search found {} results", initial_results.len());
    assert!(
        !initial_results.is_empty(),
        "Initial search should find results"
    );

    // Step 4: Start FSW
    println!("üëÅÔ∏è  Starting FSW...");
    let mut watcher = FileWatcher::new(codebase_path.to_path_buf());
    watcher
        .start(2000) // 2 second debounce
        .expect("Failed to start FSW");

    // Step 5: Add unique test content to file
    let unique_string_1 = "/// FSW_TEST_UNIQUE_ADDITION_20240209_ABC123";
    let unique_string_2 = "/// This content was added for FSW incremental indexing test";
    let add_content = format!("\n{}\n{}\n", unique_string_1, unique_string_2);

    println!("‚úèÔ∏è  Adding test content to file...");
    append_to_file(&lib_rs, &add_content);

    // Step 6: Wait for FSW to detect and process the change
    // Wait for debounce (2s) + processing time
    println!("‚è≥ Waiting for FSW to process change (15s)...");
    thread::sleep(Duration::from_secs(15));

    // Step 7: Poll FSW events and process them (simulating what IndexManager does)
    println!("üîÑ Processing FSW events...");
    let events = watcher.poll_events();
    println!("   FSW detected {} events", events.len());

    // Process events (simulating IndexManager background task)
    if !events.is_empty() {
        for event in events {
            use codesearch::watch::FileEvent;
            match event {
                FileEvent::Modified(path) => {
                    println!("   Processing modification: {}", path.display());

                    // Re-index the modified file (this is what IndexManager does)
                    let content = fs::read_to_string(&path).unwrap();
                    let chunker = SemanticChunker::new();
                    let chunks = chunker.chunk(&path, &content).unwrap();

                    // Delete old chunks for this file
                    let mut vector_store = stores.vector_store.write().await;
                    let mut fts_store = stores.fts_store.write().await;
                    let embedding_service = EmbeddingService::new(model).unwrap();

                    // Delete by path
                    vector_store.delete_by_path(&path).unwrap();
                    fts_store.delete_by_path(&path).unwrap();

                    // Add new chunks
                    for chunk in chunks {
                        let embedding = embedding_service.embed(&chunk.text).unwrap();
                        vector_store.add_chunk(&chunk, &embedding).unwrap();
                        fts_store.add_chunk(&chunk).unwrap();
                    }
                }
                FileEvent::Deleted(path) => {
                    println!("   Processing deletion: {}", path.display());
                    let mut vector_store = stores.vector_store.write().await;
                    let mut fts_store = stores.fts_store.write().await;
                    vector_store.delete_by_path(&path).unwrap();
                    fts_store.delete_by_path(&path).unwrap();
                }
                FileEvent::Renamed(_, _) => {
                    // Handle rename if needed
                }
            }
        }
    }

    // Step 8: Search for the added content (simulating MCP semantic_search tool)
    println!("üîç Searching for added content...");
    let search_add = SearchOptions {
        query: "FSW_TEST_UNIQUE_ADDITION_20240209".to_string(),
        max_results: 5,
        ..Default::default()
    };

    let add_results = search_hybrid(&stores.vector_store, &stores.fts_store, &search_add, model)
        .expect("Search for added content failed");

    println!("   Found {} results for added content", add_results.len());

    // Step 9: Verify the added content is found
    let found_add = add_results.iter().any(|r| {
        r.path.ends_with("lib.rs")
            && (r.text.contains(unique_string_1) || r.text.contains(unique_string_2))
    });

    assert!(
        found_add,
        "Added content should be found in search results.\n\
         Query: '{}'\n\
         Found {} results\n\
         Unique string to find: '{}'",
        search_add.query,
        add_results.len(),
        unique_string_1
    );

    println!("‚úÖ Added content found successfully!");

    // Step 10: Search for code structure that should exist
    let search_code = SearchOptions {
        query: "authenticate_user method authentication service".to_string(),
        max_results: 5,
        ..Default::default()
    };

    let code_results = search_hybrid(&stores.vector_store, &stores.fts_store, &search_code, model)
        .expect("Search for code structure failed");

    println!("üîç Found {} results for code structure", code_results.len());
    assert!(
        !code_results.is_empty(),
        "Code structure search should find results"
    );

    // Step 11: Verify find_references works (simulating MCP find_references tool)
    println!("üîç Testing find_references for 'authenticate_user'...");
    let refs_results = search_hybrid(
        &stores.vector_store,
        &stores.fts_store,
        &SearchOptions {
            query: "authenticate_user function call usage".to_string(),
            max_results: 10,
            ..Default::default()
        },
        model,
    )
    .expect("Find references failed");

    println!("   Found {} references", refs_results.len());

    // Step 12: Remove the added content
    println!("‚úèÔ∏è  Removing test content from file...");
    remove_last_lines(&lib_rs, 2);

    // Step 13: Wait for FSW to detect deletion
    println!("‚è≥ Waiting for FSW to process deletion (15s)...");
    thread::sleep(Duration::from_secs(15));

    // Step 14: Process FSW events for deletion
    println!("üîÑ Processing FSW events for deletion...");
    let delete_events = watcher.poll_events();
    println!("   FSW detected {} events", delete_events.len());

    if !delete_events.is_empty() {
        for event in delete_events {
            use codesearch::watch::FileEvent;
            if let FileEvent::Modified(path) = event {
                println!("   Processing modification (deletion): {}", path.display());

                // Re-index after deletion (same as add - just re-process the file)
                let content = fs::read_to_string(&path).unwrap();
                let chunker = SemanticChunker::new();
                let chunks = chunker.chunk(&path, &content).unwrap();

                let mut vector_store = stores.vector_store.write().await;
                let mut fts_store = stores.fts_store.write().await;
                let embedding_service = EmbeddingService::new(model).unwrap();

                // Delete old chunks
                vector_store.delete_by_path(&path).unwrap();
                fts_store.delete_by_path(&path).unwrap();

                // Add new chunks (file is now smaller)
                for chunk in chunks {
                    let embedding = embedding_service.embed(&chunk.text).unwrap();
                    vector_store.add_chunk(&chunk, &embedding).unwrap();
                    fts_store.add_chunk(&chunk).unwrap();
                }
            }
        }
    }

    // Step 15: Search again for the removed content (simulating MCP semantic_search)
    println!("üîç Searching for removed content...");
    let search_remove = SearchOptions {
        query: "FSW_TEST_UNIQUE_ADDITION_20240209".to_string(),
        max_results: 5,
        ..Default::default()
    };

    let remove_results = search_hybrid(
        &stores.vector_store,
        &stores.fts_store,
        &search_remove,
        model,
    )
    .expect("Search for removed content failed");

    println!(
        "   Found {} results for removed content",
        remove_results.len()
    );

    // Step 16: Verify the removed content is NOT found
    let found_remove = remove_results.iter().any(|r| {
        r.path.ends_with("lib.rs")
            && (r.text.contains(unique_string_1) || r.text.contains(unique_string_2))
    });

    assert!(
        !found_remove,
        "Removed content should NOT be found in search results.\n\
         Query: '{}'\n\
         Found {} results\n\
         Unique string that should NOT be found: '{}'",
        search_remove.query,
        remove_results.len(),
        unique_string_1
    );

    println!("‚úÖ Removed content successfully removed from index!");

    // Step 17: Stop FSW
    println!("üõë Stopping FSW...");
    watcher.stop();

    println!("\n‚úÖ FSW Incremental Indexing Test PASSED!");
    println!("   - File changes detected by FSW");
    println!("   - Index updated automatically");
    println!("   - Search results reflect changes");
    println!("   - Deletions properly removed");
}

#[test]
#[ignore] // Requires model download
fn test_fsw_multiple_changes() {
    // Test that FSW handles multiple rapid changes correctly
    let temp_dir = create_test_project();
    let codebase_path = temp_dir.path();
    let db_path = codebase_path.join(".codesearch.db");

    // Create initial index
    let model = ModelType::default();
    let dimensions = model.dimensions();
    let stores = Arc::new(SharedStores::new(&db_path, dimensions).unwrap());

    let walker = FileWalker::new(codebase_path);
    let (files, _stats) = walker.walk().unwrap();

    {
        let vector_store = stores.vector_store.read().await;
        let fts_store = stores.fts_store.read().await;
        let embedding_service = EmbeddingService::new(model).unwrap();
        let chunker = SemanticChunker::new();

        for file in files {
            let content = fs::read_to_string(&file.path).unwrap();
            let chunks = chunker.chunk(&file.path, &content).unwrap();

            for chunk in chunks {
                let embedding = embedding_service.embed(&chunk.text).unwrap();
                vector_store.add_chunk(&chunk, &embedding).unwrap();
                fts_store.add_chunk(&chunk).unwrap();
            }
        }
    }

    // Start FSW
    let mut watcher = FileWatcher::new(codebase_path.to_path_buf());
    watcher.start(1000).unwrap(); // 1 second debounce

    let lib_rs = codebase_path.join("lib.rs");

    // Add multiple changes rapidly
    for i in 1..=3 {
        let content = format!("\n/// MULTIPLE_CHANGE_TEST_{}_\n", i);
        append_to_file(&lib_rs, &content);
        thread::sleep(Duration::from_millis(500)); // Rapid changes
    }

    // Wait for FSW to debounce and process all changes
    thread::sleep(Duration::from_secs(5));

    let events = watcher.poll_events();
    println!("FSW detected {} events from multiple changes", events.len());

    // All changes should be processed in a single batch after debounce
    assert!(
        events.len() <= 2, // May get 1-2 events (batched)
        "FSW should batch multiple rapid changes, got {} events",
        events.len()
    );

    watcher.stop();
    println!("‚úÖ Multiple changes test PASSED!");
}

#[test]
#[ignore] // Requires model download
fn test_fsw_no_false_positives() {
    // Test that FSW doesn't process ignored files
    let temp_dir = TempDir::new().expect("Failed to create temp dir");
    let codebase_path = temp_dir.path();
    let db_path = codebase_path.join(".codesearch.db");

    // Create a test file
    let test_file = codebase_path.join("test.txt");
    fs::write(&test_file, "initial content").unwrap();

    // Create index
    let model = ModelType::default();
    let dimensions = model.dimensions();
    let stores = Arc::new(SharedStores::new(&db_path, dimensions).unwrap());

    let walker = FileWalker::new(codebase_path);
    let (files, _stats) = walker.walk().unwrap();

    if !files.is_empty() {
        let vector_store = stores.vector_store.read().await;
        let fts_store = stores.fts_store.read().await;
        let embedding_service = EmbeddingService::new(model).unwrap();
        let chunker = SemanticChunker::new();

        for file in files {
            let content = fs::read_to_string(&file.path).unwrap();
            let chunks = chunker.chunk(&file.path, &content).unwrap();

            for chunk in chunks {
                let embedding = embedding_service.embed(&chunk.text).unwrap();
                vector_store.add_chunk(&chunk, &embedding).unwrap();
                fts_store.add_chunk(&chunk).unwrap();
            }
        }
    }

    // Start FSW
    let mut watcher = FileWatcher::new(codebase_path.to_path_buf());
    watcher.start(1000).unwrap();

    // Modify an ignored file (create a binary-ish file with no extension)
    let ignored_file = codebase_path.join("ignored_binary");
    fs::write(&ignored_file, "binary data").unwrap();

    thread::sleep(Duration::from_secs(3));

    let events = watcher.poll_events();
    let ignored_events: Vec<_> = events
        .iter()
        .filter(|e| matches!(e, codesearch::watch::FileEvent::Modified(p) if p == &ignored_file))
        .collect();

    assert!(
        ignored_events.is_empty(),
        "FSW should not process ignored files, but found {} events",
        ignored_events.len()
    );

    watcher.stop();
    println!("‚úÖ No false positives test PASSED!");
}
